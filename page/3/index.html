<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Seite 3 | darion.johannes.yaphet</title>
  <meta name="author" content="Darion Yaphet">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="darion.johannes.yaphet"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="darion.johannes.yaphet" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">darion.johannes.yaphet</a></h1>
  <h2><a href="/">long is the way and hard  that out of Hell leads up to light</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-10T13:23:20.000Z"><a href="/2016/05/10/storage/dynamo/">2016-05-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/10/storage/dynamo/"></a></h1>
  

    </header>
    <div class="entry">
      
        <p>##Dynamo</p>
<p>###INTRODUCTION</p>
<p>Dynamo, a highly available key-value storage system that some of Amazon’s<br>core services use to provide an “always-on” experience.</p>
<p>To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use. </p>
<p>###Peer to Peer Systems</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-10T13:23:20.000Z"><a href="/2016/05/10/storage/level/">2016-05-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/10/storage/level/"></a></h1>
  

    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-10T13:23:20.000Z"><a href="/2016/05/10/storage/cassandra/">2016-05-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/10/storage/cassandra/"></a></h1>
  

    </header>
    <div class="entry">
      
        <p>##Cassandra </p>
<p>###Introduction</p>
<p>Cassandra is a peer-to-peer distributed data store with column oriented database system.  </p>
<p>Cassandra is developed by using Google Big table and  Amazon ‘s Dynamo distribution model.  </p>
<p>All writes are automatically partitioned and replicated throughout the cluster. </p>
<p>Client read or write requests can go to any node in the cluster. It is shared nothing architecture.</p>
<p>Cassandra is designed to handle big data workloads across multiple nodes with no single point of failure.<br>Cassandra addresses the problem of failures by employing a peer-to-peer distributed system across<br>homogeneous nodes where data is distributed among all nodes in the cluster. </p>
<p>A sequentially written commit log on each node captures write activity to ensure data durability. Data is then indexed and written to an in-memory structure, called<br>a <code>memtable</code>, which resembles a write-back cache. Once the memory structure is full, the data is written to disk in an <code>SSTable</code> data file. </p>
<p>All writes are automatically partitioned and replicated throughout the cluster. Using a process called <code>compaction</code> Cassandra periodically consolidates SSTables, discarding obsolete data and tombstones</p>
<p>###gossip: Internode communications</p>
<p><code>Gossip</code> is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. </p>
<p>The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn<br>about all other nodes in the cluster. </p>
<p>A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node.To prevent problems in gossip communications, use the same list of seed nodes for all nodes in a cluster.This is most critical the first time a node starts up. </p>
<p>By default, a node remembers other nodes it has<br>gossiped with between subsequent restarts. The seed node designation has no purpose other than<br>bootstrapping the gossip process for new nodes joining the cluster. Seed nodes are not a single point<br>of failure, nor do they have any other special purpose in cluster operations beyond the bootstrapping of<br>nodes.</p>
<p>####Failure detection and recovery<br>Failure detection is a method for <code>locally determining from gossip state and history</code> if another node in the system is up or down.</p>
<p>Cassandra uses this information to avoid routing client requests to unreachable nodes whenever possible.Uses an <code>accrual detection mechanism</code> to calculate a per-node threshold that takes into account network performance, workload, and historical conditions.Every node maintains <code>a sliding window of inter-arrival times of gossip messages</code> from other nodes in the cluster.</p>
<p>###Virtual nodes</p>
<p>###Write </p>
<p>Cassandra processes data at several stages on the write path, starting with the immediate logging of a write and ending in compaction</p>
<ol>
<li>Logging data in the commit log</li>
<li>Writing data to the memtable</li>
<li>Flushing data from the memtable</li>
<li>Storing data on disk in SSTables</li>
<li>Compaction</li>
</ol>
<p>Cassandra stores the data in a structure in memory, the memtable, and also appends writes to the commit log on disk.</p>
<p>When memtable contents exceed a configurable threshold, the memtable data, which includes indexes, is put in a queue to be flushed to disk.<code>Typically, before restarting nodes, flushing the memtable is recommended to reduce commit log replay time.</code></p>
<p>SSTables are immutable, not written to again after the memtable is flushed.</p>
<p>###Read </p>
<p>###Delete</p>
<p>Cassandra can have an optional expiration date called TTL (time to live) and marks TTL data with a tombstone after the requested amount of time has expired.  After data is marked with a tombstone, the data is automatically removed during the normal <code>compaction</code> process.</p>
<p>###Compaction</p>
<p>###Hinted Handoff</p>
<p>Hinted Handoff is an optional part of writes in Cassandra, enabled by default, with two purposes:</p>
<p>Hinted handoff allows Cassandra to offer full write availability when consistency is not required.</p>
<p>Hinted handoff dramatically improves response consistency after temporary outages such as network failures.</p>
<p>All hints for a given replica are stored under a single partition key, so replaying hints is a simple sequential read with minimal performance impact.</p>
<p><a href="http://www.datastax.com/dev/blog/modern-hinted-handoff" target="_blank" rel="external">http://www.datastax.com/dev/blog/modern-hinted-handoff</a></p>
<p>###SSTable</p>
<p>SSTables have 3 separate files created per column-family.</p>
<ol>
<li>Bloom Filter</li>
<li>Index</li>
<li>Data</li>
</ol>
<p>The format of a SSTable component file is<br><code>&lt;keyspace&gt;-&lt;column family&gt;-[tmp marker]-&lt;version&gt;-&lt;generation&gt;-&lt;component&gt;.db</code></p>
<p>###Memtable</p>
<p>###CQL<br>Cassandra Query Language is the default and primary interface into the Cassandra DBMS. </p>
<p>CQL and SQL share the same abstract idea of a table constructed of tables and rows. </p>
<p>The Cassandra keyspace is a namespace that defines how data is replicated on nodes.Typically, a cluster has one keyspace per application. Replication is controlled on a per-keyspace basis, so data that has different replication requirements typically resides in different keyspaces. </p>
<p>Keyspaces are not designed to be used as a significant map layer within the data model. Keyspaces are designed to control data replication for a set of tables.</p>
<p>To use NetworkTopologyStrategy for production use, you need to change the default snitch, SimpleSnitch, to a network-aware snitch, define one or more data center names in the snitch properties file, and use the data center name(s) to define the keyspace</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE keyspace_name.table_name </span><br><span class="line">( column_definition, column_definition, ...)</span><br><span class="line">WITH property AND property ...</span><br></pre></td></tr></table></figure>
<p>column_definition is:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">column_name cql_type</span><br><span class="line">| column_name cql_type PRIMARY KEY</span><br><span class="line">| PRIMARY KEY ( partition_key )</span><br><span class="line">| column_name collection_type</span><br></pre></td></tr></table></figure>
<p>partition_key is:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">column_name</span><br><span class="line">| ( column_name1</span><br><span class="line">        , column_name2, column_name3 ... )</span><br><span class="line">| ((column_name1*, column_name2*), column3*, column4* . . . )</span><br></pre></td></tr></table></figure>
<p>collection_type is:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LIST &lt;cql_type&gt;</span><br><span class="line">| SET &lt;cql_type&gt;</span><br><span class="line">| MAP &lt;cql_type, cql_type&gt;</span><br></pre></td></tr></table></figure>
<p><code>CREATE TYPE</code>  Create a user-defined type</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TYPE IF NOT EXISTS keyspace.type_name ( field, field, ...)</span><br></pre></td></tr></table></figure>
<p>Example :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TYPE address (</span><br><span class="line">  street text,</span><br><span class="line">  city text,</span><br><span class="line">  zip_code int,</span><br><span class="line">  phones set&lt;text&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">λ ~/source/apache-cassandra-2.2.1/ bin/cqlsh</span><br><span class="line">Connected to Test Cluster at 127.0.0.1:9042.</span><br><span class="line">[cqlsh 5.0.1 | Cassandra 2.2.1 | CQL spec 3.3.0 | Native protocol v4]</span><br><span class="line">Use HELP for help.</span><br><span class="line">cqlsh&gt;</span><br><span class="line">cqlsh&gt;</span><br><span class="line">cqlsh&gt; CREATE KEYSPACE mykeyspace</span><br><span class="line">   ... WITH REPLICATION = &#123; &apos;class&apos; : &apos;SimpleStrategy&apos;, &apos;replication_factor&apos; : 1 &#125;;</span><br><span class="line">cqlsh&gt;</span><br><span class="line">cqlsh&gt;</span><br><span class="line">cqlsh&gt; use mykeyspace ;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt; CREATE TABLE users (</span><br><span class="line">              ...   user_id int PRIMARY KEY,</span><br><span class="line">              ...   fname text,</span><br><span class="line">              ...   lname text</span><br><span class="line">              ... );</span><br><span class="line"></span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt; INSERT INTO users (user_id,  fname, lname)</span><br><span class="line">              ...   VALUES (1745, &apos;john&apos;, &apos;smith&apos;);</span><br><span class="line">cqlsh:mykeyspace&gt; INSERT INTO users (user_id,  fname, lname)</span><br><span class="line">              ...   VALUES (1744, &apos;john&apos;, &apos;doe&apos;);</span><br><span class="line">cqlsh:mykeyspace&gt; INSERT INTO users (user_id,  fname, lname)</span><br><span class="line">              ...   VALUES (1746, &apos;john&apos;, &apos;smith&apos;);</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt; SELECT * FROM users;</span><br><span class="line"></span><br><span class="line"> user_id | fname | lname</span><br><span class="line">---------+-------+-------</span><br><span class="line">    1745 |  john | smith</span><br><span class="line">    1744 |  john |   doe</span><br><span class="line">    1746 |  john | smith</span><br><span class="line"></span><br><span class="line">(3 rows)</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt; SELECT * FROM users WHERE  user_id = 1744;</span><br><span class="line"></span><br><span class="line"> user_id | fname | lname</span><br><span class="line">---------+-------+-------</span><br><span class="line">    1744 |  john |   doe</span><br><span class="line"></span><br><span class="line">(1 rows)</span><br><span class="line">cqlsh:mykeyspace&gt; CREATE INDEX ON users (lname);</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt; SELECT * FROM users WHERE lname = &apos;smith&apos;;</span><br><span class="line"></span><br><span class="line"> user_id | fname | lname</span><br><span class="line">---------+-------+-------</span><br><span class="line">    1745 |  john | smith</span><br><span class="line">    1746 |  john | smith</span><br><span class="line"></span><br><span class="line">(2 rows)</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br><span class="line">cqlsh:mykeyspace&gt;</span><br></pre></td></tr></table></figure>
<p>###Cassandra tools</p>
<p>The nodetool utility is a command line interface for managing a cluster.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodetool -h HOSTNAME [-p JMX_PORT ] COMMAND</span><br></pre></td></tr></table></figure>
<p>Most nodetool commands operate on a single node in the cluster if -h is not used to identify one or more other nodes. These commands operate cluster-wide<br><code>rebuild repair taketoken</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">bin/nodetool help</span><br><span class="line">usage: nodetool [(-pwf &lt;passwordFilePath&gt; | --password-file &lt;passwordFilePath&gt;)]</span><br><span class="line">        [(-pw &lt;password&gt; | --password &lt;password&gt;)] [(-h &lt;host&gt; | --host &lt;host&gt;)]</span><br><span class="line">        [(-u &lt;username&gt; | --username &lt;username&gt;)] [(-p &lt;port&gt; | --port &lt;port&gt;)]</span><br><span class="line">        &lt;command&gt; [&lt;args&gt;]</span><br><span class="line"></span><br><span class="line">The most commonly used nodetool commands are:</span><br><span class="line">    assassinate                  Forcefully remove a dead node without re-replicating any data.  Use as a last resort if you cannot removenode</span><br><span class="line">    bootstrap                    Monitor/manage node&apos;s bootstrap process</span><br><span class="line">    cleanup                      Triggers the immediate cleanup of keys no longer belonging to a node. By default, clean all keyspaces</span><br><span class="line">    clearsnapshot                Remove the snapshot with the given name from the given keyspaces. If no snapshotName is specified we will remove all snapshots</span><br><span class="line">    compact                      Force a (major) compaction on one or more tables</span><br><span class="line">    compactionhistory            Print history of compaction</span><br><span class="line">    compactionstats              Print statistics on compactions</span><br><span class="line">    decommission                 Decommission the *node I am connecting to*</span><br><span class="line">    describecluster              Print the name, snitch, partitioner and schema version of a cluster</span><br><span class="line">    describering                 Shows the token ranges info of a given keyspace</span><br><span class="line">    disableautocompaction        Disable autocompaction for the given keyspace and table</span><br><span class="line">    disablebackup                Disable incremental backup</span><br><span class="line">    disablebinary                Disable native transport (binary protocol)</span><br><span class="line">    disablegossip                Disable gossip (effectively marking the node down)</span><br><span class="line">    disablehandoff               Disable storing hinted handoffs</span><br><span class="line">    disablethrift                Disable thrift server</span><br><span class="line">    drain                        Drain the node (stop accepting writes and flush all tables)</span><br><span class="line">    enableautocompaction         Enable autocompaction for the given keyspace and table</span><br><span class="line">    enablebackup                 Enable incremental backup</span><br><span class="line">    enablebinary                 Reenable native transport (binary protocol)</span><br><span class="line">    enablegossip                 Reenable gossip</span><br><span class="line">    enablehandoff                Reenable the future hints storing on the current node</span><br><span class="line">    enablethrift                 Reenable thrift server</span><br><span class="line">    flush                        Flush one or more tables</span><br><span class="line">    gcstats                      Print GC Statistics</span><br><span class="line">    getcompactionthreshold       Print min and max compaction thresholds for a given table</span><br><span class="line">    getcompactionthroughput      Print the MB/s throughput cap for compaction in the system</span><br><span class="line">    getendpoints                 Print the end points that owns the key</span><br><span class="line">    getlogginglevels             Get the runtime logging levels</span><br><span class="line">    getsstables                  Print the sstable filenames that own the key</span><br><span class="line">    getstreamthroughput          Print the Mb/s throughput cap for streaming in the system</span><br><span class="line">    gossipinfo                   Shows the gossip information for the cluster</span><br><span class="line">    help                         Display help information</span><br><span class="line">    info                         Print node information (uptime, load, ...)</span><br><span class="line">    invalidatecountercache       Invalidate the counter cache</span><br><span class="line">    invalidatekeycache           Invalidate the key cache</span><br><span class="line">    invalidaterowcache           Invalidate the row cache</span><br><span class="line">    join                         Join the ring</span><br><span class="line">    listsnapshots                Lists all the snapshots along with the size on disk and true size.</span><br><span class="line">    move                         Move node on the token ring to a new token</span><br><span class="line">    netstats                     Print network information on provided host (connecting node by default)</span><br><span class="line">    pausehandoff                 Pause hints delivery process</span><br><span class="line">    proxyhistograms              Print statistic histograms for network operations</span><br><span class="line">    rangekeysample               Shows the sampled keys held across all keyspaces</span><br><span class="line">    rebuild                      Rebuild data by streaming from other nodes (similarly to bootstrap)</span><br><span class="line">    rebuild_index                A full rebuild of native secondary indexes for a given table</span><br><span class="line">    refresh                      Load newly placed SSTables to the system without restart</span><br><span class="line">    reloadtriggers               Reload trigger classes</span><br><span class="line">    removenode                   Show status of current node removal, force completion of pending removal or remove provided ID</span><br><span class="line">    repair                       Repair one or more tables</span><br><span class="line">    resetlocalschema             Reset node&apos;s local schema and resync</span><br><span class="line">    resumehandoff                Resume hints delivery process</span><br><span class="line">    ring                         Print information about the token ring</span><br><span class="line">    scrub                        Scrub (rebuild sstables for) one or more tables</span><br><span class="line">    setcachecapacity             Set global key, row, and counter cache capacities (in MB units)</span><br><span class="line">    setcachekeystosave           Set number of keys saved by each cache for faster post-restart warmup. 0 to disable</span><br><span class="line">    setcompactionthreshold       Set min and max compaction thresholds for a given table</span><br><span class="line">    setcompactionthroughput      Set the MB/s throughput cap for compaction in the system, or 0 to disable throttling</span><br><span class="line">    sethintedhandoffthrottlekb   Set hinted handoff throttle in kb per second, per delivery thread.</span><br><span class="line">    setlogginglevel              Set the log level threshold for a given class. If both class and level are empty/null, it will reset to the initial configuration</span><br><span class="line">    setstreamthroughput          Set the Mb/s throughput cap for streaming in the system, or 0 to disable throttling</span><br><span class="line">    settraceprobability          Sets the probability for tracing any given request to value. 0 disables, 1 enables for all requests, 0 is the default</span><br><span class="line">    snapshot                     Take a snapshot of specified keyspaces or a snapshot of the specified table</span><br><span class="line">    status                       Print cluster information (state, load, IDs, ...)</span><br><span class="line">    statusbackup                 Status of incremental backup</span><br><span class="line">    statusbinary                 Status of native transport (binary protocol)</span><br><span class="line">    statusgossip                 Status of gossip</span><br><span class="line">    statushandoff                Status of storing future hints on the current node</span><br><span class="line">    statusthrift                 Status of thrift server</span><br><span class="line">    stop                         Stop compaction</span><br><span class="line">    stopdaemon                   Stop cassandra daemon</span><br><span class="line">    tablehistograms              Print statistic histograms for a given table</span><br><span class="line">    tablestats                   Print statistics on tables</span><br><span class="line">    toppartitions                Sample and print the most active partitions for a given column family</span><br><span class="line">    tpstats                      Print usage statistics of thread pools</span><br><span class="line">    truncatehints                Truncate all hints on the local node, or truncate hints for the endpoint(s) specified.</span><br><span class="line">    upgradesstables              Rewrite sstables (for the requested tables) that are not on the current version (thus upgrading them to said current version)</span><br><span class="line">    verify                       Verify (check data checksum for) one or more tables</span><br><span class="line">    version                      Print cassandra version</span><br><span class="line"></span><br><span class="line">See &apos;nodetool help &lt;command&gt;&apos; for more information on a specific command.</span><br></pre></td></tr></table></figure>
<p>###Architecture</p>
<p>###Authentication</p>
<p>To Configure Cassandra to use internal authentication,</p>
<p>###Virtual Nodes</p>
<p>Prior to Cassandra 1.2, each node was assigned to a specific token range. Now each node can support <code>multiple</code>, <code>non-contiguous</code> token ranges. Instead of a node being responsible for one large range of tokens, it is responsible for many smaller ranges. In this way, one physical node is essentially hosting many smaller <code>&quot;virtual&quot; nodes</code>.</p>
<p>Cassandra predetermines the size of each virtual node. You can control the number of virtual nodes assigned to each physical node.</p>
<p><img src="../resource/cassandra/vnodes.png" alt="VNode"></p>
<p>####JVM Turning</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>####Config<br>Property     | Description<br>:———– | :———–<br>cluster_name| name of the cluster<br>num_tokens| number of tokens randomly assigned to this node on the ring<br>initial_token| specify tokens manually<br>hinted_handoff_enabled|<br>max_hint_window_in_ms|<br>hinted_handoff_throttle_in_kb|<br>max_hints_delivery_threads|number of threads to deliver hints<br>batchlog_replay_throttle_in_kb|<br>authenticator|<code>AllowAllAuthenticator</code> set it to disable authentication ,<code>PasswordAuthenticator</code> username/password pairs to authenticate<br>authorizer|<br>role_manager|maintain grants and memberships between roles<br>roles_validity_in_ms|<br>roles_update_interval_in_ms|<br>permissions_validity_in_ms|refresh interval for roles cache<br>permissions_update_interval_in_ms|refresh interval for permissions cache<br>partitioner|distributing groups of rows across nodes<br>data_file_directories|store data on disk<br>commitlog_directory|<br>disk_failure_policy|policy for data disk failures<br>commit_failure_policy|policy for commit disk failures<br>key_cache_size_in_mb|max size of the key cache in memory<br>key_cache_save_period|<br>key_cache_keys_to_save|number of keys to save<br>row_cache_class_name|row cache implementation class name<br>row_cache_size_in_mb|max size of the row cache in memory<br>row_cache_save_period|<br>row_cache_keys_to_save|number of keys from the row cache to save<br>counter_cache_size_in_mb|max size of the counter cache in memory<br>counter_cache_save_period|seconds save the counter cache<br>counter_cache_keys_to_save|number of keys from the counter cache to save<br>memory_allocator|off-heap memory allocator<br>saved_caches_directory| saved caches<br>commitlog_sync|<code>periodic</code> writes may be acked immediately  <code>batch</code> won’t ack writes until the commit log has been fsynced to disk<br>commitlog_sync_period_in_ms|<br>commitlog_segment_size_in_mb|size of commitlog file segments<br>commitlog_compression|compression commit log<br>seed_provider|<br>concurrent_reads|<br>concurrent_writes|<br>concurrent_counter_writes|<br>file_cache_size_in_mb|<br>memtable_heap_space_in_mb|<br>memtable_offheap_space_in_mb|<br>memtable_cleanup_threshold|<br>memtable_allocation_type|specify the way allocates and manages memtable memory<br>commitlog_total_space_in_mb|total space to use for commit logs on disk<br>memtable_flush_writers|the amount of memtable flush writer threads<br>index_summary_capacity_in_mb|<br>index_summary_resize_interval_in_minutes|<br>trickle_fsync|<br>trickle_fsync_interval_in_kb|<br>storage_port|<br>ssl_storage_port|<br>listen_address|<br>broadcast_address|<br>internode_authenticator|<br>start_native_transport|<br>native_transport_port|<br>native_transport_max_threads|<br>native_transport_max_frame_size_in_mb|<br>native_transport_max_concurrent_connections|<br>native_transport_max_concurrent_connections_per_ip|<br>start_rpc|<br>rpc_address|<br>rpc_port|<br>rpc_keepalive|<br>rpc_server_type|<br>rpc_min_threads|<br>rpc_max_threads|<br>rpc_send_buff_size_in_bytes|<br>rpc_recv_buff_size_in_bytes|<br>internode_send_buff_size_in_bytes|<br>internode_recv_buff_size_in_bytes|<br>thrift_framed_transport_size_in_mb|<br>incremental_backups|<br>snapshot_before_compaction|<br>auto_snapshot|<br>tombstone_warn_threshold|<br>tombstone_failure_threshold|<br>column_index_size_in_kb|<br>batch_size_warn_threshold_in_kb|<br>batch_size_fail_threshold_in_kb|<br>concurrent_compactors|<br>compaction_throughput_mb_per_sec|<br>compaction_large_partition_warning_threshold_mb|<br>sstable_preemptive_open_interval_in_mb|<br>stream_throughput_outbound_megabits_per_sec|<br>inter_dc_stream_throughput_outbound_megabits_per_sec|<br>read_request_timeout_in_ms|<br>range_request_timeout_in_ms|<br>write_request_timeout_in_ms|<br>counter_write_request_timeout_in_ms|<br>cas_contention_timeout_in_ms|<br>truncate_request_timeout_in_ms|<br>request_timeout_in_ms|<br>cross_node_timeout|<br>streaming_socket_timeout_in_ms|<br>phi_convict_threshold|<br>endpoint_snitch|<br>dynamic_snitch_update_interval_in_ms|<br>dynamic_snitch_reset_interval_in_ms|<br>dynamic_snitch_badness_threshold|<br>request_scheduler|<br>request_scheduler_options|<br>request_scheduler_id|<br>server_encryption_options|<br>client_encryption_options|<br>internode_compression|<br>inter_dc_tcp_nodelay|<br>tracetype_query_ttl|<br>tracetype_repair_ttl|<br>enable_user_defined_functions|<br>windows_timer_interval|</p>
<p>####Inner Cassandra </p>
<p>#####StartUp</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-10T13:23:20.000Z"><a href="/2016/05/10/storage/mysql/">2016-05-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/10/storage/mysql/"></a></h1>
  

    </header>
    <div class="entry">
      
        <p>##MySQL</p>
<h3 id="Create"><a href="#Create" class="headerlink" title="Create"></a>Create</h3><h3 id="Grant"><a href="#Grant" class="headerlink" title="Grant"></a>Grant</h3><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><h3 id="内存表"><a href="#内存表" class="headerlink" title="内存表"></a>内存表</h3><p><code>内存表</code>与<code>临时表</code>并不相同，临时表也是存放在内存中，临时表最大所需内存需要通过tmp_table_size = 128M设定。当数据超过临时表的最大值设定时，自动转为磁盘表，此时因需要进行IO操作，性能会大大下降，而内存表不会，内存表满后，会提示数据满错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table test</span><br><span class="line">(</span><br><span class="line">  id int unsigned not null auto_increment primary key,</span><br><span class="line">  state char(10),</span><br><span class="line">  type char(20),</span><br><span class="line">  date char(30)</span><br><span class="line">)ENGINE=MEMORY DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure>
<p>Reference :</p>
<ol>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA5ODM5MDU3MA==&amp;mid=402904260&amp;idx=2&amp;sn=19ba9befd5258cfe01f58fceedec3ca6&amp;scene=23&amp;srcid=0405r4HLfjqqjCpxVFFDrzYA#rd" target="_blank" rel="external">由 B-/B+ 树看 MySQL 索引结构</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA5ODM5MDU3MA==&amp;mid=2650861618&amp;idx=2&amp;sn=8cb8851f579b73eaf4b71734a106fda8&amp;scene=23&amp;srcid=0509sGaRSxN1PQK2Vk65Uiqw#rd" target="_blank" rel="external">MySQL 内存表的特性与使用介绍</a></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-10T13:23:20.000Z"><a href="/2016/05/10/storage/redis/">2016-05-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/10/storage/redis/"></a></h1>
  

    </header>
    <div class="entry">
      
        <p>##Redis</p>
<p>####Benchmarks</p>
<p>Redis includes the redis-benchmark utility that simulates running commands done by N clients at the same time sending M total queries.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Usage: redis-benchmark [-h &lt;host&gt;] [-p &lt;port&gt;] [-c &lt;clients&gt;] [-n &lt;requests]&gt; [-k &lt;boolean&gt;]</span><br><span class="line"></span><br><span class="line"> -h &lt;hostname&gt;      Server hostname (default 127.0.0.1)</span><br><span class="line"> -p &lt;port&gt;          Server port (default 6379)</span><br><span class="line"> -s &lt;socket&gt;        Server socket (overrides host and port)</span><br><span class="line"> -a &lt;password&gt;      Password for Redis Auth</span><br><span class="line"> -c &lt;clients&gt;       Number of parallel connections (default 50)</span><br><span class="line"> -n &lt;requests&gt;      Total number of requests (default 100000)</span><br><span class="line"> -d &lt;size&gt;          Data size of SET/GET value in bytes (default 2)</span><br><span class="line"> -dbnum &lt;db&gt;        SELECT the specified db number (default 0)</span><br><span class="line"> -k &lt;boolean&gt;       1=keep alive 0=reconnect (default 1)</span><br><span class="line"> -r &lt;keyspacelen&gt;   Use random keys for SET/GET/INCR, random values for SADD</span><br><span class="line">  Using this option the benchmark will expand the string __rand_int__</span><br><span class="line">  inside an argument with a 12 digits number in the specified range</span><br><span class="line">  from 0 to keyspacelen-1. The substitution changes every time a command</span><br><span class="line">  is executed. Default tests use this to hit random keys in the</span><br><span class="line">  specified range.</span><br><span class="line"> -P &lt;numreq&gt;        Pipeline &lt;numreq&gt; requests. Default 1 (no pipeline).</span><br><span class="line"> -q                 Quiet. Just show query/sec values</span><br><span class="line"> --csv              Output in CSV format</span><br><span class="line"> -l                 Loop. Run the tests forever</span><br><span class="line"> -t &lt;tests&gt;         Only run the comma separated list of tests. The test</span><br><span class="line">                    names are the same as the ones produced as output.</span><br><span class="line"> -I                 Idle mode. Just open N idle connections and wait.</span><br></pre></td></tr></table></figure>
<p>####Cluster</p>
<p>####Hyperloglog</p>
<p><code>Hyperloglog</code> is an approximate technique for computing the number of distinct entries in a set, It does this while using a small amount of memory. For instance, to achieve 99% accuracy, it needs only 16 KB.</p>
<hr>
<p>####FAQ</p>
<p><a href="https://github.com/antirez/redis/issues/2902" target="_blank" rel="external">Does FLUSHDB command stop the ping/pong message?</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Redis is single-threaded. Every command will block other clients. </span><br><span class="line"></span><br><span class="line">If your FLUSHDB takes a long time, Sentinel/Cluster might see that node as down, as it doesn&apos;t respond to pings anymore.</span><br><span class="line"></span><br><span class="line">Soon you will be able to use FLUSHDB LAZY to lazily flush the database without blocking it for a long time.</span><br></pre></td></tr></table></figure>
<hr>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-06T15:28:48.000Z"><a href="/2016/05/06/algorithms/hidden-markov-model/">2016-05-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/06/algorithms/hidden-markov-model/"></a></h1>
  

    </header>
    <div class="entry">
      
        <h3 id="Hidden-Markov-Model"><a href="#Hidden-Markov-Model" class="headerlink" title="Hidden Markov Model"></a>Hidden Markov Model</h3><p>Reference :</p>
<ol>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzI2NjA3NTc4Ng==&amp;mid=2652077944&amp;idx=1&amp;sn=d17758f0aed8670ba0f5f41e481f0205&amp;scene=23&amp;srcid=0506YCgtc3T5Bwj2Bwrn2fn7#rd" target="_blank" rel="external">如何用简单易懂的例子解释隐马尔可夫模型</a></li>
<li></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-04-30T16:00:00.000Z"><a href="/2016/05/01/distribution/hbase/">2016-05-01</a></time>
      
      
  
    <h1 class="title"><a href="/2016/05/01/distribution/hbase/">HBase</a></h1>
  

    </header>
    <div class="entry">
      
        <h3 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h3><h4 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h4><p>HBase中不存在单点问题，集群中可以启动多个HMaster实例。</p>
<p>一个实例作为Master使用，其他作为backup。</p>
<h4 id="HRegionServer"><a href="#HRegionServer" class="headerlink" title="HRegionServer"></a>HRegionServer</h4><p>HRegionServer响应Client请求，完成数据读写操作。</p>
<h4 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h4><p>Zookeeper 中存储-ROOT-表，.META.表</p>
<p>HRegionServer把自己以Ephedral方式注册到Zookeeper中，HMaster随时感知各个HRegionServer的健康状况<br>Zookeeper避免HMaster单点问题</p>
<p>AssignmentManager 管理&amp;负责Region分配</p>
<p>TableLockManager  管理分布式表级锁</p>
<p>RegionStates  在内存中存储Region状态  在AssignmentManager中跟踪Region状态</p>
<p>HRegionInfo  含有Region信息  Region包含一个完整键空间</p>
<p>RegionName含有：</p>
<p>tableName   : The name of the table</p>
<p>startKey    : The startKey for the region.</p>
<p>regionId    : A timestamp when the region is created.</p>
<p>replicaId   : An id starting from 0 to differentiate replicas of the same region range but hosted in separated servers. The same region range can be hosted in multiple locations.</p>
<p>createRegionName </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public interface TableLock &#123;</span><br><span class="line">    void acquire() throws IOException;</span><br><span class="line">    void release() throws IOException;                </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>HBase is composed of three types of servers in a master slave type of architecture. Region servers serve data for reads and writes. When accessing data, clients communicate with HBase RegionServers directly. Region assignment, DDL (create, delete tables) operations are handled by the HBase Master process. Zookeeper, which is part of HDFS, maintains a live cluster state.</p>
<p><a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" target="_blank" rel="external">https://www.mapr.com/blog/in-depth-look-hbase-architecture</a></p>
<h4 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Table (HBase table)</span><br><span class="line">  Region (Regions for the table)  </span><br><span class="line">    Store (Store per ColumnFamily for each Region for the table)    </span><br><span class="line">      MemStore (MemStore for each Store for each Region for the tale)</span><br><span class="line">      StoreFile (StoreFiles for each Store for each Region for the tab          le)      </span><br><span class="line">        Block(Blocks within a StoreFile within a Store for each Region for the table)</span><br></pre></td></tr></table></figure>
<h4 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h4><p>需要确保主从cluster上有相同的Table 且Table结构一致 都是enable 版本都在0.90.0之上 主从机器两两互通  master cluster hbase-site.xml 中添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>进入master cluster shell 中 执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_peer &apos;1&apos;,&quot;slave:2181/slave-zk-parent&quot;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="Bucket-Cache"><a href="#Bucket-Cache" class="headerlink" title="Bucket Cache"></a>Bucket Cache</h4><p><img src="resource/hbase/cache.png" alt="HBase Cache"></p>
<h4 id="HBase-ZooKeeper-ZNode"><a href="#HBase-ZooKeeper-ZNode" class="headerlink" title="HBase ZooKeeper ZNode"></a>HBase ZooKeeper ZNode</h4><table>
<thead>
<tr>
<th>Path</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>/hbase (zookeeper.znode.parent)</td>
<td>The root znode that will contain all the znodes created/used by HBase</td>
</tr>
<tr>
<td>/hbase/hbaseid (zookeeper.znode.clusterId)</td>
<td>Initialized by the Master with the UUID that identifies the cluster.The ID is also stored on HDFS in hdfs:/<namenode>:<port>/hbase/hbase.id.</port></namenode></td>
</tr>
<tr>
<td>/hbase/root-region-server (zookeeper.znode.rootserver)</td>
<td>Contains the location of the server hosting the ROOT region. It is queried by the client to identify the RegionServer responsible for ROOT and ask for the META locations.</td>
</tr>
<tr>
<td>/hbase/rs (zookeeper.znode.rs)</td>
<td>On startup each RegionServer will create a sub-znode that is supposed to describe the “online” state of the RegionServer. The master monitors this znode to get the “online” RegionServer list and use that during Assignment/Balancing.</td>
</tr>
<tr>
<td>/hbase/unassigned (zookeeper.znode.unassigned)</td>
<td>Contains a sub-znode for each unassigned region . This znode is used by the Assignment Manager to discover the regions to assign.</td>
</tr>
<tr>
<td>/hbase/master (zookeeper.znode.master)</td>
<td>The “active” master will register its own address in this znode at startup, making this znode the source of truth for identifying which server is the Master.</td>
</tr>
<tr>
<td>/hbase/backup-masters (zookeeper.znode.backup.masters)</td>
<td>Each inactive Master will register itself as backup Master by creating a sub-znode. This znode is mainly used to track which machines are available to replace the Master in case of failure.</td>
</tr>
<tr>
<td>/hbase/shutdown (zookeeper.znode.state)</td>
<td>Describes the cluster state, “Is the cluster up?” It is created by the Master on startup and deleted by the Master on shutdown. It is watched by the RegionServers.</td>
</tr>
<tr>
<td>/hbase/draining (zookeeper.znode.draining.rs)</td>
<td>Used to decommission more than one RegionServer at a time by creating sub-znodes with the form serverName,port,startCode .</td>
</tr>
<tr>
<td>/hbase/table (zookeeper.znode.masterTableEnableDisable)</td>
<td>Used by the master to track the table state during assignments .</td>
</tr>
<tr>
<td>/hbase/splitlog (zookeeper.znode.splitlog)</td>
<td>Used by the log splitter to track the pending log to replay and its assignment.</td>
</tr>
<tr>
<td>/hbase/acl (zookeeper.znode.acl.parent)</td>
<td>The acl znode is used for synchronizing the changes made to the <em>acl</em> table by the grant/revoke commands.</td>
</tr>
<tr>
<td>/hbase/tokenauth (zookeeper.znode.tokenauth.parent)</td>
<td>The token provider is usually used to allow a MapReduce job to access the HBase cluster.</td>
</tr>
<tr>
<td>/hbase/replication (zookeeper.znode.replication)</td>
<td>Root znode that contains all HBase replication state information</td>
</tr>
<tr>
<td>/hbase/replication/peers (zookeeper.znode.replication.peers)</td>
<td>Each peer will have a sub-znode containing the ZK ensemble’s addresses that allows the peer to be contacted.</td>
</tr>
<tr>
<td>/hbase/replication/peers/<clusterid>/peer-state (zookeeper.znode.replication.peers.state)</clusterid></td>
<td>Mirror of the /hbase/replication/peers znode, but here each sub-znode will track the peer enabled/disabled state.</td>
</tr>
<tr>
<td>/hbase/replication/state (zookeeper.znode.replication.state)</td>
<td>Indicates whether replication is enabled. Replication can be enabled by setting the hbase.replication configuration to true, or can be enabled/disabled by using the start/stop command in the HBase shell.</td>
</tr>
<tr>
<td>/hbase/replication/rs (zookeeper.znode.replication.rs)</td>
<td>Contains the list of RegionServers in the main cluster .</td>
</tr>
<tr>
<td>/hbase/online-snapshot/acquired</td>
<td>The acquired znode describes the first step of a snapshot transaction. The Master will create a sub-znode for the snapshot.</td>
</tr>
<tr>
<td>/hbase/online-snapshot/reached</td>
<td>Once each RegionServer has joined the acquired znode, the Master will create the reached znode for the snapshot telling each RegionServer that it is time to finalize/commit the snapshot.</td>
</tr>
<tr>
<td>/hbase/online-snapshot/abort</td>
<td>If something fails on the Master side or the RegionServer side, the abort znode will be created for the snapshot telling everyone that something went wrong with the snapshot and to abort the job.</td>
</tr>
</tbody>
</table>
<p>Reference :</p>
<p>1.<a href="http://blog.cloudera.com/blog/2013/10/what-are-hbase-znodes/" target="_blank" rel="external">What are HBase znodes?</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-04-27T10:55:35.000Z"><a href="/2016/04/27/distribution/mesos/">2016-04-27</a></time>
      
      
  
    <h1 class="title"><a href="/2016/04/27/distribution/mesos/"></a></h1>
  

    </header>
    <div class="entry">
      
        <h3 id="Mesos"><a href="#Mesos" class="headerlink" title="Mesos"></a>Mesos</h3><p>Mesos 被定义为一个<code>分布式系统内核</code>。它和 Linux 内核设计原则相同，只是设计在不同的抽象层级上。</p>
<p>Mesos 运行在服务器集群上并且通过 API 的形式给诸如 Hadoop，Spark 等应用提供资源管理、任务调度等功能。</p>
<p><img src="resource/mesos/architecture.jpg" alt="Architect"></p>
<p>Mesos采用了<code>master/slave</code>结构，master做得尽可能地轻量级，其上面所有的元数据可通过各个slave重新注册而进行重构，故很容易通过zookeeper解决该单点故障问题。</p>
<p>Mesos 基本术语：</p>
<ol>
<li>Mesos Master主要负责管理各个framework和slave，并将slave上的资源分配给各个framework.</li>
<li>Mesos Slave负责管理本节点上的各个mesos-task，比如：为各个executor分配资源</li>
<li>Framework Hadoop，Spark等计算框架,通过MesosSchedulerDiver接入Mesos.</li>
<li>Executor 执行器 Mesos Slave上，用于启动计算框架中的task</li>
</ol>
<p>Mesos Master是系统核心，负责管理接入各个framework和 slave 并将slave资源分配给framework.Mesos Slave负责接收并执行来自Mesos Master命令,管理节点上的Mesos Task</p>
<h4 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h4><p>Reference :</p>
<ol>
<li><a href="http://geek.csdn.net/news/detail/54860" target="_blank" rel="external">Mesos社区与生态</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653547005&amp;idx=1&amp;sn=5a0be692f731aa7bfae030555423ecc6&amp;scene=23&amp;srcid=0427A8Bvm3NJTtHzx3pCXasW#rd" target="_blank" rel="external">Mesos架构与去哪儿的统一框架实践</a></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-04-23T12:45:20.000Z"><a href="/2016/04/23/distribution/akka/">2016-04-23</a></time>
      
      
  
    <h1 class="title"><a href="/2016/04/23/distribution/akka/"></a></h1>
  

    </header>
    <div class="entry">
      
        <h3 id="Actor-Modle"><a href="#Actor-Modle" class="headerlink" title="Actor Modle"></a>Actor Modle</h3><p>The Actor Model takes a different approach to solving the problem of concurrency,<br>by avoiding the issues caused by threads and locks. In the Actor Model, all objects<br>are modeled as independent, computational entities that only respond to the<br>messages received. </p>
<p>Actors change their state only when they receive a stimulus in the form of a message. </p>
<p>The Actor Model is based on the following principles:</p>
<ol>
<li>The immutable messages are used to communicate between actors. </li>
<li>Each actor has a queue attached where the incoming messages are enqueued. </li>
<li>Messages are passed between actors asynchronously. </li>
<li>Communication between the sender and receiver is decoupled and<br>asynchronous, allowing them to execute in different threads. </li>
</ol>
<p>Actors can change their state and behavior based on the message passed. </p>
<p>The connection wire between the sender sending a<br>message and the receiver actor receiving the message is called the mailbox. </p>
<h3 id="Akka"><a href="#Akka" class="headerlink" title="Akka"></a>Akka</h3><p>The Akka framework has taken the “Actor Model” concept to build an<br>event-driven, middleware framework that allows the building of concurrent,<br>scalable, and distributed systems. </p>
<p>The Akka framework provides the following features:</p>
<ol>
<li><p><code>Concurrency</code>: The Akka Actor Model abstracts concurrency handling and<br>allows the programmer to focus on the business logic</p>
</li>
<li><p><code>Scalability</code>: The Akka Actor Model’s asynchronous message passing allows<br>applications to scale up on multicore servers</p>
</li>
<li><p><code>Fault tolerance</code>: Akka borrows the concepts and techniques from Erlang to<br>build the “Let It Crash”, fault tolerance model</p>
</li>
<li><p><code>Event-driven architecture</code>: Akka provides an asynchronous messaging<br>platform for building event-driven architectures</p>
</li>
<li><p><code>Transaction support</code>: Akka implements transactors that combine the actors<br>and software transactional memory (STM) into transactional actors</p>
</li>
<li><p><code>Location transparency</code>: Akka provides a unified programming model for<br>multicore and distributed computing needs</p>
</li>
<li><p><code>Scala/Java APIs</code>: Akka supports both Java and Scala APIs for<br>building applications</p>
</li>
</ol>
<h4 id="Akka-Use-Case"><a href="#Akka-Use-Case" class="headerlink" title="Akka Use Case"></a>Akka Use Case</h4><ul>
<li>Transaction processing</li>
<li>Service providers</li>
<li>Batch processing</li>
<li>Data mining/analytics/Business Intelligence</li>
<li>Service gateways/hubs</li>
<li>Apps requiring concurrency/parallelism</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">akka.protocol://system@host:1234/user/my/actor/hierarchy/path</span><br></pre></td></tr></table></figure>
<p>Actors can change their state and behavior based on the message passed.</p>
<p>Behavior is nothing but the computation logic that needs to be executed in response<br>to the message received.</p>
<h3 id="Actor-Lifecycle"><a href="#Actor-Lifecycle" class="headerlink" title="Actor Lifecycle"></a>Actor Lifecycle</h3><p>(!)</p>
<p>Akka provides hooks such as preStart that allow the actor’s state and behavior to be initialized. </p>
<p>When the actor is stopped, Akka disables the message queuing for the actor before<br>PostStop is invoked. In the postStop hook, any persistence of the state or clean up<br>of any hold-up resources can be done</p>
<p>An actor’s lifecycle consists of three phases :</p>
<ul>
<li>Actor is initialized and started</li>
<li>Actor receives and processes messages by executing a specific behavior</li>
<li>Actor stops itself when it receives a termination message</li>
</ul>
<p><code>preStart()</code> and <code>postStop()</code> can be implemented to <code>initialize/clean</code> any resources used by the actor to process the messages.</p>
<p><code>preRestart()</code> and <code>postRestart()</code> allow the actor to manage the state in case an exception has been raised and Supervisor actor restarts the actor.</p>
<h3 id="Defining-an-actor"><a href="#Defining-an-actor" class="headerlink" title="Defining an actor"></a>Defining an actor</h3><p>All actors are created in the <code>context</code> of an actor system or another actor. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ActorSystem _system = ActorSystem.create(&quot;MyActorSystem&quot;);</span><br><span class="line">ActorRef myActor = _system.actorOf(new Props(MyActor.class),&quot;myActor&quot;);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val system = ActorSystem(&quot;MyActorSystem&quot;)</span><br><span class="line">val myActor = system.actorOf(Props[MyActor], name = &quot;myActor&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="Stopping-actor"><a href="#Stopping-actor" class="headerlink" title="Stopping actor"></a>Stopping actor</h4><h4 id="Killing-actor"><a href="#Killing-actor" class="headerlink" title="Killing actor"></a>Killing actor</h4><p>An actor can be killed when a kill() message is sent to it. </p>
<p><code>PoisonPill</code> is an asynchronous way to shut down the actor. <code>kill()</code>  is a synchronous way.</p>
<h4 id="HotSwap"><a href="#HotSwap" class="headerlink" title="HotSwap"></a>HotSwap</h4><h3 id="Fault-tolerance"><a href="#Fault-tolerance" class="headerlink" title="Fault tolerance"></a>Fault tolerance</h3><p>This actor hierarchy forms the basis of the Akka’s <code>&quot;Let It Crash&quot;</code> fault-tolerance<br>model. </p>
<p>Akka’s fault-tolerance model is built using the <code>actor hierarchy</code> and <code>supervisor model</code>. </p>
<h3 id="Location-transparency"><a href="#Location-transparency" class="headerlink" title="Location transparency"></a>Location transparency</h3><p>Akka uses the same philosophy of the WWW to identify and locate resources on the Web.</p>
<p>Akka uses the similar URL convention to locate the actors. The default values are <code>akka://hostname/</code> or <code>akka://hostname:2552/</code></p>
<h3 id="Actor-System"><a href="#Actor-System" class="headerlink" title="Actor System"></a>Actor System</h3><hr>
<p>Akka uses the Actor Model together with Software Transactional Memory to raise the abstraction level and provide a better platform to build correct concurrent and scalable applications.</p>
<p>For fault-tolerance Akka adopts the “Let it crash”, also called “Embrace failure”, model which have been used with great success in the telecom industry to build applications that self-heals, systems that never stop.</p>
<hr>
<blockquote>
<p>The <code>actor</code> model in computer science is a mathematical model of concurrent computation that treats “actors” as the universal primitives of concurrent computation</p>
</blockquote>
<p>Actors can be created:</p>
<ul>
<li>Extending the ‘Actor’ class and implementing the ‘receive’ method.</li>
<li>Create an anonymous Actor using one of the ‘actor’ methods.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class MyActor extends Actor &#123;</span><br><span class="line">  def receive = &#123;</span><br><span class="line">    case &quot;test&quot; =&gt; println(&quot;received test&quot;)</span><br><span class="line">    case _      =&gt; println(&quot;received unknown message&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">val myActor = new MyActor</span><br><span class="line">myActor.start</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val myActor = actor &#123; </span><br><span class="line">  case &quot;test&quot; =&gt; println(&quot;received test&quot;)</span><br><span class="line">  case _      =&gt; println(&quot;received unknown message&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Akka’s approach to fault-tolerance; the “let it crash” model, is implemented by linking Actors.</p>
<h4 id="Actor"><a href="#Actor" class="headerlink" title="Actor"></a>Actor</h4><p>An actor can change another actor’s state only by sending it a message. Actors communicate with other actors using the <code>address</code> of the target actor’s mailbox. Communication between actors is completely asynchronous and non-blocking; actors only react to the messages being sent to them.</p>
<h6 id="Typed-Actor"><a href="#Typed-Actor" class="headerlink" title="Typed Actor"></a>Typed Actor</h6><p>In Akka, <code>typed actors</code> have been implemented using the Active Object pattern. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">The Active Object Design pattern decouples method execution from method invocation, which reside in their own threads of control. </span><br><span class="line"></span><br><span class="line">The goal is to introduce concurrency and fault tolerance, by using asynchronous method invocation and a scheduler for handling requests.</span><br><span class="line"></span><br><span class="line">The key objective of the Active Object pattern is to decouple the method execution</span><br><span class="line">from the method invocation.</span><br></pre></td></tr></table></figure>
<p><code>Active Object pattern</code> decouples the method invocation from method execution :</p>
<ol>
<li>The client calls the proxy object and invokes the method</li>
<li>The proxy in passes the method calls as method requests to a scheduler or invocation handler that intercepts the call</li>
<li>Scheduler or invocation handler enqueues the method requests on a queue</li>
<li>The scheduler continuously monitors the queue and determines which method request(s) have become runnable</li>
<li>Scheduler or invocation handler dispatches the requests to the implementation object</li>
<li>The implementation object, running on the same thread as the scheduler, processes the request and returns any value to the client as Future</li>
</ol>
<p><code>Proxy instance</code> has an associated invocation handler. </p>
<p><code>Method invocation</code> is dispatched to the invoke method of the instance’s invocation handler. </p>
<p>Actors are entities that change their state by processing the incoming messages and generating other messages in response.</p>
<p>Use <code>typed actors</code> sparingly and avoid blocking behavior by writing methods that either return Unit or Future.</p>
<p>Typed Actor Model is communication via method calls. The parameter values are the messages and these need to be <code>immutable</code>. </p>
<p>Messages can be passed to an actor in two modes:</p>
<ol>
<li>Fire and forget (the caller of the method does not expect any reply)</li>
<li>Send and receive (the caller of the method expects a reply from the implementation class and will wait for that reply)</li>
</ol>
<p><strong>Actor lifecycle monitoring</strong></p>
<p><code>TypedActor.PreStart</code> and <code>TypedActor.PostStop</code> interfaces, we can add the required functionality before the actor starts responding to the method calls</p>
<p><code>TypedActor.PreRestart</code> and <code>TypedActor.PostRestart</code> interfaces to add functionality on actor restart as part of the supervision</p>
<p><strong>Receiving messages</strong></p>
<p>Typed actors can implement the <code>akka.actor.TypedActor.Receiver</code> interface in<br>order to process messages coming to them.</p>
<p><strong>Supervisor strategy</strong></p>
<p>Akka’s “Let It Crash” model is implemented by linking actors in a hierarchy. </p>
<p><strong>Using dispatchers</strong><br>A dispatcher controls and coordinates the message dispatching to the actors that is<br>mapped on the underlying threads. </p>
<p><strong>Using routers</strong></p>
<p>A router is also a type of actor, which routes the incoming messages to the outbound actors. </p>
<hr>
<p>Dispatchers are the heart of the Akka application and this is what makes it<br>humming.</p>
<p>Routers on the other hand, route incoming messages to outbound actors. </p>
<h4 id="Dispatchers"><a href="#Dispatchers" class="headerlink" title="Dispatchers"></a>Dispatchers</h4><p>A dispatcher controls and coordinates the message dispatching to the actors that is<br>mapped on the underlying threads. </p>
<p>The dispatchers run on their threads &amp; dispatch the actors and messages from the attached mailbox and allocate on heap to the executor threads. </p>
<p>The executor threads are configured and tuned to the underlying processor cores that available for processing the messages.</p>
<p>In Akka, a router is also a type of actor, which <code>routes the incoming messages to the outbound actors</code>. </p>
<p>Dispatchers are used to control the <code>flow of execution</code>. Based on the dispatching policy, dispatchers will <code>route the incoming message or request to the business process</code>. </p>
<ul>
<li>Centralized control</li>
<li>Application partitioning</li>
<li>Reduced inter-dependencies<br>less contention on the same resources,leading to a scalable model.</li>
</ul>
<p><code>Types of dispatchers</code></p>
<p>There are 4 different types of message dispatchers</p>
<ol>
<li>Dispatcher</li>
<li>PinnedDispatcher</li>
<li>Balancing dispatcher</li>
<li>Calling thread dispatcher</li>
</ol>
<p>And  there are four default mailbox implementations provided as follows:</p>
<ol>
<li>Unbounded mailbox</li>
<li>Bounded mailbox</li>
<li>Unbounded priority mailbox</li>
<li>Bounded priority mailbox</li>
</ol>
<p>An event-based dispatcher that binds a set of actors to a thread pool backed up by a BlockingQueue method.</p>
<ol>
<li>Every actor is backed by its own mailbox</li>
<li>The dispatcher can be shared with any number of actors</li>
<li>The dispatcher can be backed by either thread pool or fork join pool</li>
<li>The dispatcher is optimized for non-blocking code</li>
</ol>
<p><code>Pinned dispatcher</code> ( single, dedicated thread for each actor)</p>
<p>This dispatcher is useful when the actors are doing I/O operations or performing long-running calculations. The dispatcher will deallocate the thread attached to the actor after a configurable period of inactivity.</p>
<ol>
<li>Every actor is backed by its own mailbox.</li>
<li>A dedicated thread for each actor implies that this dispatcher cannot be shared with any other actors.</li>
<li>The dispatcher is backed by the thread pool executor.</li>
<li>The dispatcher is optimized for blocking operations. </li>
</ol>
<p><code>Balancing dispatcher</code> ( event-based dispatcher that tries to redistribute work from busy actors and allocate it to idle ones)</p>
<p>Redistribution of tasks can only work if all actors are of the same type </p>
<p>The dispatcher looks for actors that are idle and dispatches the message to them for processing.</p>
<ol>
<li>There is only one mailbox for all actors</li>
<li>The dispatcher can be shared only with actors of the same type</li>
<li>The dispatcher can be backed by a either thread pool or fork join pool</li>
</ol>
<p><code>Calling thread dispatcher</code> ( runs the task execution on the current thread only)</p>
<p><strong>Types of mailboxes</strong></p>
<ol>
<li>Blocking queue means a queue that waits for space to become available before putting in an element and similarly waits for the queue to become non-empty before retrieving an element</li>
<li>Bounded queue means a queue that limits the size of the queue; meaning you cannot add more elements than the specified size</li>
</ol>
<p><strong>Types of Executor</strong></p>
<ol>
<li>Thread pool executor ( Tasks are assigned to the pool using a queue. )</li>
<li>Fork join executor ( Based on the premise of divide-and-conquer)</li>
</ol>
<p><code>Fork join executor</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> # Configuration for the fork join pool</span><br><span class="line"> fork-join-executor &#123;</span><br><span class="line"> </span><br><span class="line">    # Min number of threads</span><br><span class="line">    parallelism-min = 2</span><br><span class="line">    </span><br><span class="line">    # available processors * factor</span><br><span class="line">    parallelism-factor = 2.0</span><br><span class="line">    </span><br><span class="line">    # Max number of threads</span><br><span class="line">    parallelism-max = 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">my-dispatcher &#123;</span><br><span class="line">    type = Dispatcher</span><br><span class="line">    executor = &quot;fork-join-executor&quot;</span><br><span class="line">    </span><br><span class="line">    fork-join-executor &#123;</span><br><span class="line">       parallelism-min = 2</span><br><span class="line">       parallelism-factor = 2.0</span><br><span class="line">       parallelism-max = 10</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    throughput = 100</span><br><span class="line">    mailbox-capacity = -1</span><br><span class="line">    mailbox-type = &quot;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">my-dispatcher &#123;</span><br><span class="line">    type = PinnedDispatcher</span><br><span class="line"></span><br><span class="line">        executor = &quot;thread-pool-executor&quot;</span><br><span class="line">        thread-pool-executor &#123;</span><br><span class="line">        core-pool-size-min = 2</span><br><span class="line">        core-pool-size-factor = 2.0</span><br><span class="line">        core-pool-size-max = 10</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    throughput = 100</span><br><span class="line">    mailbox-capacity = -1</span><br><span class="line">    mailbox-type =&quot;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Routers"><a href="#Routers" class="headerlink" title="Routers"></a>Routers</h3><p>An entity that directs the message from the source to the destination actor. </p>
<p>Routers route incoming messages to outbound actors.</p>
<p>Router is also a type of actor, which routes the incoming messages to the outbound actors.</p>
<p>For the router, the outbound actors are also called routees. </p>
<p>Akka router supports the following :</p>
<ol>
<li>Round robin router ( routes the incoming messages in a circular order to all its routees)</li>
<li>Random router ( randomly selects a routee and routes the message to the same)</li>
<li>Smallest mailbox router ( identifies the actor with the least number of messages in its mailbox and routes the message to the same)</li>
<li>Broadcast router ( forwards the same message to all the routees)</li>
<li>Scatter gather first completed router ( forwards the message to all its routees as a future, then whichever routee actor responds back, it takes the results and sends them back to the caller)</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MyRouterExample&#123;</span><br><span class="line">    akka.actor.deployment &#123;</span><br><span class="line">        /myRandomRouterActor &#123;</span><br><span class="line">            router = random</span><br><span class="line">            nr-of-instances = 5</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Dynamically resizing routers</strong></p>
<p>To handle the variability of the incoming message traffic, it might be important to increase the number of actors available to handle the load at runtime. </p>
<p>For this, routers provide a construct called resize, which allows us to define the range bound in terms of minimum and maximum instances.</p>
<hr>
<h4 id="Supervision-and-Monitoring"><a href="#Supervision-and-Monitoring" class="headerlink" title="Supervision and Monitoring"></a>Supervision and Monitoring</h4><p><code>When an actor crashes or throws an exception, who is responsible to catch
the exception?</code></p>
<h4 id="Actor-hierarchy"><a href="#Actor-hierarchy" class="headerlink" title="Actor hierarchy"></a>Actor hierarchy</h4><p>The design idea of the Actor Model is to break down the large task into smaller tasks to the point where the task is granular and structured enough to be performed by one specialized actor.</p>
<h4 id="Supervision"><a href="#Supervision" class="headerlink" title="Supervision"></a>Supervision</h4><h4 id="Supervision-strategies"><a href="#Supervision-strategies" class="headerlink" title="Supervision strategies"></a>Supervision strategies</h4><p>Akka provides two supervision strategies:</p>
<ul>
<li><code>One-For-One strategy</code> the supervision strategy is applied only to the failed child. (default)</li>
<li><code>All-For-One strategy</code> the supervision strategy is applied to all the actor siblings.</li>
</ul>
<h4 id="Software-Transactional-Memory"><a href="#Software-Transactional-Memory" class="headerlink" title="Software Transactional Memory"></a>Software Transactional Memory</h4><p>Transactions provide a mechanism to manage the application access to data in a multiuser environment</p>
<p><img src="resource/akka/supervision_strategies.jpg" alt="supervision_strategies"></p>
<hr>
<h4 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h4><p>Akka Cluster provides a fault-tolerant decentralized peer-to-peer based cluster membership service with no single point of failure or single point of bottleneck.</p>
<p>A cluster is made up of a set of member nodes. The identifier for each node is a <code>hostname:port:uid</code> tuple.</p>
<p><strong>Gossip</strong></p>
<p>In <code>push-pull gossip</code> a digest is sent representing current versions but not actual values; the recipient of the gossip can then send back any values for which it has newer versions and also request values for which it has outdated versions. Akka uses a single shared state with a vector clock for versioning, so the variant of push-pull gossip used in Akka makes use of this version to only push the actual state as needed.</p>
<p>Each node chooses another random node to initiate a round of gossip with.</p>
<p>The gossip messages are serialized with <code>protobuf</code> and also <code>gzipped</code> to reduce payload size.</p>
<p><strong>Vector Clocks</strong></p>
<p><strong>Gossip Convergence</strong></p>
<p><strong>Failure Detector</strong></p>
<p><strong>Leader</strong></p>
<p><strong>Seed Nodes</strong></p>
<p>When a new node is started it sends a message to all seed nodes and then sends a join command to the seed node that answers first.</p>
<p><strong>Gossip Protocol</strong></p>
<p><strong>Membership Lifecycle</strong></p>
<p><img src="resource/akka/member-states-weakly-up.png" alt="member-states-weakly-up"></p>
<p><img src="resource/akka/member-states.png" alt="member-states"></p>
<p><strong>Member States</strong></p>
<table>
<thead>
<tr>
<th>Terms</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>joining</td>
<td>transient state when joining a cluster</td>
</tr>
<tr>
<td>weakly up</td>
<td>transient state while network split</td>
</tr>
<tr>
<td>up</td>
<td>normal operating state</td>
</tr>
<tr>
<td>leaving / exiting</td>
<td>states during graceful removal</td>
</tr>
<tr>
<td>down</td>
<td>marked as down</td>
</tr>
<tr>
<td>removed</td>
<td>tombstone state </td>
</tr>
</tbody>
</table>
<p><strong>User Actions</strong></p>
<table>
<thead>
<tr>
<th>Terms</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>join</td>
<td>join a single node to a cluster</td>
</tr>
<tr>
<td>leave</td>
<td>tell a node to leave the cluster gracefully</td>
</tr>
<tr>
<td>down</td>
<td>mark a node as down</td>
</tr>
</tbody>
</table>
<p><strong>Distributed Publish Subscribe in Cluster</strong></p>
<p><strong>Cluster Client</strong></p>
<p>Communication from an actor system that is not part of the cluster to actors running somewhere in the cluster. </p>
<p>The client does not have to know on which node the destination actor is running.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-Dcom.sun.management.jmxremote.port=9999 </span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=false </span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=false</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h4><p><strong>Core concepts</strong></p>
<table>
<thead>
<tr>
<th>Terms</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stream</td>
<td></td>
</tr>
<tr>
<td>Element</td>
<td></td>
</tr>
<tr>
<td>Back-pressure</td>
<td></td>
</tr>
<tr>
<td>Non-Blocking</td>
<td></td>
</tr>
<tr>
<td>Graph</td>
<td></td>
</tr>
<tr>
<td>Processing Stage</td>
<td></td>
</tr>
<tr>
<td>Source</td>
<td></td>
</tr>
<tr>
<td>Sink</td>
<td></td>
</tr>
<tr>
<td>Flow</td>
<td></td>
</tr>
<tr>
<td>RunnableGraph</td>
<td></td>
</tr>
</tbody>
</table>
<hr>
<ol>
<li><code>node</code> : A logical member of a cluster. There could be multiple nodes on a physical machine. Defined by a hostname:port:uid tuple.</li>
<li><code>cluster</code> : A set of nodes joined together through the membership service.</li>
<li><code>leader</code> : A single node in the cluster that acts as the leader. Managing cluster convergence and membership state transitions.</li>
</ol>
<hr>
<h3 id="Managing-application-configuration"><a href="#Managing-application-configuration" class="headerlink" title="Managing application configuration"></a>Managing application configuration</h3><p>Akka provides a powerful mechanism called extensions. </p>
<p>Extensions are loaded in a static way with only one instance per ActorSystem. </p>
<p>Extensions are implemented as a factory pattern. </p>
<p>Akka extensions are comprised of two parts, given as follows:</p>
<ol>
<li>Extension ( Extension is the interface that needs to be implemented by the class and registered with ActorSystem, and ActorSystem will register the class and make the result available.)</li>
<li>ExtensionId (It is the unique ID of the extension that is used to identify the<br>extension within ActorSystem.)</li>
</ol>
<p><strong>Trace</strong></p>
<p>Tracing is disabled by default, so we need to enable it for the specific actor systems that need to be monitored</p>
<p>Define the node property for each node in the system, as this is used to identify and tag the multiple actor systems that are running</p>
<p>Define the MongoDB name and URL, specifying the location of MongoDB</p>
<p><strong>Analyze</strong></p>
<p>A span is the path between two trace events, and the duration between these events is the data that captures the essence of the availability and scalability of the application.</p>
<p><strong>Query</strong></p>
<p><strong>JMX</strong></p>
<p><strong>Durable mailboxes</strong></p>
<p><strong>Actors and web applications</strong></p>
<p><strong>Integrating actors with ZeroMQ</strong></p>
<hr>
<p><strong>Persistence</strong></p>
<p>Akka persistence is that only changes to an actor’s internal state are persisted but never its current state directly.</p>
<ol>
<li><p>PersistentActor <code>When a persistent actor is started or restarted, journaled messages are replayed to that actor so that it can recover internal state from these messages.</code></p>
</li>
<li><p>PersistentView <code>A view itself does not journal new messages, it updates internal state only from a persistent actor&#39;s replicated message stream.</code></p>
</li>
<li><p>AtLeastOnceDelivery <code>in case of sender and receiver JVM crashes</code></p>
</li>
<li><p>AsyncWriteJournal <code>A journal stores the sequence of messages sent to a persistent actor.Journal maintains highestSequenceNr that is increased on each message.The persistence extension comes with a &quot;leveldb&quot; journal plugin, which writes to the local filesystem.</code></p>
</li>
<li><p>Snapshot store <code>Snapshots are used for optimizing recovery times.The persistence extension comes with a &quot;local&quot; snapshot storage plugin, which writes to the local filesystem.</code></p>
</li>
</ol>
<p><strong>Event sourcing</strong></p>
<p>Akka persistence supports event sourcing with the <code>PersistentActor</code> trait.</p>
<p>An actor that extends this trait uses the <code>persist</code> method to persist and handle events.</p>
<p><strong>Identifiers</strong></p>
<p>A persistent actor must have an identifier that doesn’t change across different actor incarnations. </p>
<p>The identifier must be defined with the persistenceId method.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">override def persistenceId = &quot;my-persistence-id&quot;</span><br></pre></td></tr></table></figure>
<p><strong>Recovery</strong></p>
<p><strong>Atomic writes</strong></p>
<p><strong>Batch writes</strong></p>
<p><strong>Message deletion</strong></p>
<p><strong>Persistence status handling</strong></p>
<p><strong>Safely shutting down persistent actors</strong></p>
<p><strong><em>Persistent Views</em></strong></p>
<p><strong>At-Least-Once Delivery</strong></p>
<p><strong>Relationship between deliver and confirmDelivery</strong></p>
<p><strong>Event Adapters</strong></p>
<p><strong>Persistent FSM</strong></p>
<p><strong>Storage plugins</strong></p>
<p><strong>Multiple persistence plugin configurations</strong></p>
<hr>
<h3 id="Actor-DSL"><a href="#Actor-DSL" class="headerlink" title="Actor DSL"></a>Actor DSL</h3><p>Actor can be created more concisely using the Act trait.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akka.actor.ActorDSL._</span><br><span class="line">import akka.actor.ActorSystem</span><br><span class="line"></span><br><span class="line">implicit val system = ActorSystem(&quot;demo&quot;)</span><br></pre></td></tr></table></figure>
<p>To define a simple actor: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val a = actor(new Act &#123;</span><br><span class="line">  become &#123;</span><br><span class="line">    case &quot;hello&quot; ⇒ sender() ! &quot;hi&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>Life-cycle management</strong></p>
<p>Life-cycle hooks are also exposed as DSL elements</p>
<p><strong>Finite State Machine</strong></p>
<p>Finite State Machine can be described as a set of relations:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">State(S) x Event(E) -&gt; Actions (A), State(S&apos;)</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference :"></a>Reference :</h4><ol>
<li><a href="https://dzone.com/articles/introducing-akka-%E2%80%93-simpler" target="_blank" rel="external">Introducing Akka – Simpler Scalability, Fault-Tolerance, Concurrency &amp; Remoting Through Actors</a></li>
<li><a href="https://en.wikipedia.org/wiki/Actor_model" target="_blank" rel="external">Actor model</a></li>
<li>Akka Essentials</li>
<li><a href="http://doc.akka.io/docs/akka/2.4.1/java.html" target="_blank" rel="external">Java Documentation</a></li>
<li><a href="http://docs.oracle.com/javase/6/docs/technotes/guides/reflection/proxy.html" target="_blank" rel="external">Implementation of Dynamic Proxy classes in JDK</a></li>
<li><a href="http://doc.akka.io/docs/akka/2.1.2/project/migration-guide-2.0.x-2.1.x.html" target="_blank" rel="external">Migration Guide 2.0.x to 2.1.x</a></li>
<li><a href="https://www.typesafe.com/blog/typesafe-announces-akka-streams" target="_blank" rel="external">Typesafe announces Akka Streams, a part of the Reactive Streams Initiative</a></li>
<li><a href="https://github.com/functional-streams-for-scala/fs2" target="_blank" rel="external">Compositional, streaming I/O library for Scala</a></li>
<li><a href="http://doc.akka.io/docs/akka/2.4.2/scala/persistence.html" target="_blank" rel="external">persistence</a></li>
<li><a href="http://doc.akka.io/docs/akka/2.4.2/scala/actordsl.html" target="_blank" rel="external">Actor DSL</a></li>
<li><a href="http://www.infoq.com/cn/presentations/akka-cluster-realization/" target="_blank" rel="external">Akka下分片集群的实现</a></li>
<li><a href="http://erlang.org/documentation/doc-4.8.2/doc/design_principles/fsm.html" target="_blank" rel="external">Erlang design principles</a></li>
<li><a href="http://letitcrash.com/post/30165507578/shutdown-patterns-in-akka-2" target="_blank" rel="external">Shutdown Patterns in Akka 2</a></li>
<li><a href="http://doc.akka.io/docs/akka/2.4.4/scala.html" target="_blank" rel="external">Akka Scala Documentation</a></li>
<li><a href="https://opencredo.com/introduction-to-akka-streams-getting-started/" target="_blank" rel="external">Introduction to Akka Streams – Getting started</a></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-04-22T14:46:44.000Z"><a href="/2016/04/22/algorithms/community-detection/">2016-04-22</a></time>
      
      
  
    <h1 class="title"><a href="/2016/04/22/algorithms/community-detection/"></a></h1>
  

    </header>
    <div class="entry">
      
        <h3 id="Community-Detection-社区发现算法"><a href="#Community-Detection-社区发现算法" class="headerlink" title="Community Detection (社区发现算法)"></a>Community Detection (社区发现算法)</h3><p>针对社区的研究实际上是从子图分割问题演化而来，Kernighan-Lin 提出的二分算法使得子图分割问题逐渐成为当时图挖掘领域关注的重点。另外，在社会学领域，社会学家也发现社区结构在各种复杂网络中的普遍存在性。进入21世纪后，社区的研究开始被研究者所重视，而近年来随着社交网络的崛起，这一领域的关注度已大大提升。</p>
<p>Reference :</p>
<ol>
<li><a href="http://senseable.mit.edu/community_detection/" target="_blank" rel="external">Community Detection - MIT Senseable City Lab</a></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/page/2/" class="alignleft prev">Vorherige Seite</a>
  
  
    <a href="/page/4/" class="alignright next">Nächste Seite</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Kategorien</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithms/">Algorithms</a><small>1</small></li>
  
    <li><a href="/categories/Distributed/">Distributed</a><small>7</small></li>
  
    <li><a href="/categories/Language/">Language</a><small>4</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>1</small></li>
  
    <li><a href="/categories/Storage/">Storage</a><small>1</small></li>
  
    <li><a href="/categories/live/">live</a><small>3</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/Algorithms/">Algorithms</a><small>1</small></li>
  
    <li><a href="/tags/Alluxio/">Alluxio</a><small>1</small></li>
  
    <li><a href="/tags/Clojure/">Clojure</a><small>1</small></li>
  
    <li><a href="/tags/Hadoop/">Hadoop</a><small>5</small></li>
  
    <li><a href="/tags/JVM/">JVM</a><small>1</small></li>
  
    <li><a href="/tags/Java/">Java</a><small>1</small></li>
  
    <li><a href="/tags/RocksDB/">RocksDB</a><small>1</small></li>
  
    <li><a href="/tags/Scala/">Scala</a><small>1</small></li>
  
    <li><a href="/tags/TensorFlow/">TensorFlow</a><small>1</small></li>
  
    <li><a href="/tags/coffee/">coffee</a><small>1</small></li>
  
    <li><a href="/tags/fitness/">fitness</a><small>1</small></li>
  
    <li><a href="/tags/game/">game</a><small>1</small></li>
  
    <li><a href="/tags/spark/">spark</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2016 Darion Yaphet
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
